{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter06.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPkvosdf86tltj4RGwY6Qoe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoon0gim/test2/blob/main/chapter06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Bag of words(Bow)"
      ],
      "metadata": {
        "id": "3_k0Z-D8x4U8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "단어의 등장 순서를 고려하지 않은 빈도수 기반의 단어 표현 방법\n",
        "1. 각 단어의 고유한 정수 인덱스를 부여\n",
        "2. 각 인덱스 위치에 단어 토큰의 등장 횟수를 기록한 벡터를 만든다."
      ],
      "metadata": {
        "id": "YCzgiTH_x8CP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = 'john likes to watch movies. Mary likes movies too'\n",
        "bow1 = {\"john\": 1, \"likes\":2,\"to\":1, \"watch\":1,\"movies\":2, \"Mary\":1,\"too\",:1 }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "8QdgAZ75x7Bi",
        "outputId": "15b5c698-b18f-4608-f05c-b1f4e8da9d46"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-ced4efb82b54>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    bow1 = {\"john\": 1, \"likes\":2,\"to\":1, \"watch\":1,\"movies\":2, \"Mary\":1,\"too\",:1 }\u001b[0m\n\u001b[0m                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VA4eEnjyUem",
        "outputId": "a517e4f6-12e8-4dba-f691-deb81542fa06"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 48.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.2.0)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.3.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "g-QUqfLiyV0T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "import re\n",
        "okt = Okt()\n",
        "\n",
        "#정규표현식을 통해 온점을 제거하는 정제 작업\n",
        "token = re.sub(\"(\\.)\", \"\", \"소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.\")\n",
        "token = okt.morphs(token) # okt 형태소 분석기"
      ],
      "metadata": {
        "id": "PQTbQvd3yXVk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IthD6PBOzD5I",
        "outputId": "65e2c8f3-bd2a-48ac-d810-3e0229441de8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['소비자', '는', '주로', '소비', '하는', '상품', '을', '기준', '으로', '물가상승률', '을', '느낀다']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2index = []\n",
        "bow = []\n",
        "\n",
        "for voca in token:\n",
        "  if voca not in word2index.keys():\n",
        "    word2index[voca] = len(word2index) # ['소비자' : 1]\n",
        "    bow.insert(len(word2index)-1, 1)\n",
        "  else:\n",
        "    index = word2index.get(voca)\n",
        "    bow[index] = bow[index]+1\n",
        "\n",
        "print(word2index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "U-YRTdNUzEVe",
        "outputId": "aad1adc3-823b-44c1-e014-a09ecca398b9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-44f0e9bcbb5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvoca\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mvoca\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword2index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mword2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvoca\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ['소비자' : 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = [\n",
        "          'John likes to watch movies',\n",
        "          'Mary likes movies too',\n",
        "          'Mary also like to watch football games'\n",
        "]\n",
        "vector = CountVectorizer()\n",
        "print(vector.fit_transform(corpus).toarray())\n",
        "print(vector.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GuaKHpg0DBl",
        "outputId": "0151d30b-bc52-4563-e076-bb44d6f60ffe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 1 0 1 0 1 1 0 1]\n",
            " [0 0 0 0 0 1 1 1 0 1 0]\n",
            " [1 1 1 0 1 0 1 0 1 0 1]]\n",
            "{'john': 3, 'likes': 5, 'to': 8, 'watch': 10, 'movies': 7, 'mary': 6, 'too': 9, 'also': 0, 'like': 4, 'football': 1, 'games': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. TF-IDF( Term-Frequency-inverse Document Frequency)\n",
        "모든 문서에 자주 등장하는 단어는 중요도가 낮다고 판단하고, 특정 문서에서만 자주 등장하는 단어는 중요도가 높다고 판단하는 것"
      ],
      "metadata": {
        "id": "MdtSZNCTIfkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import log\n",
        "import pandas as pd\n",
        "\n",
        "docs = [\n",
        "        'John likes to watch movies and Mary likes movies too',\n",
        "        'James likes to watch TV',\n",
        "        'Mary also likes to watch football games'\n",
        "]"
      ],
      "metadata": {
        "id": "-xcul-pRDAWk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = list(set(w for doc in docs for w in doc.split()))\n",
        "vocab.sort()\n"
      ],
      "metadata": {
        "id": "9eFc6ktJI1yc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어장의 크기 :', len(vocab))\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wc-7YIFgJMsP",
        "outputId": "97b9dfbf-dae4-4e70-f853-698538ed3852"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어장의 크기 : 13\n",
            "['James', 'John', 'Mary', 'TV', 'also', 'and', 'football', 'games', 'likes', 'movies', 'to', 'too', 'watch']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = len(docs)\n",
        "N"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-9H9lNPJRiI",
        "outputId": "3210e634-73b6-45e2-dde2-9f20ee116026"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. tf(d, t) : 특정 문서 d에서의 특정 단어 t의 등장 횟수\n",
        "2. df(t) : 특정 단어 t가 등장한 문서 수\n",
        "3. idf(d,t) : df(t)에 반비례하는 수\n",
        "\n",
        "idf(d,t) = log n/1+df(t)"
      ],
      "metadata": {
        "id": "YaCqjxu8JfLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tf(t, d): # 특정 문서 d에서의 특정 단어 t의 등장 횟수\n",
        "  return d.count(t)"
      ],
      "metadata": {
        "id": "qCyDFtXYJeJM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def idf(t): \n",
        "  df = 0 # 특정 단어 t가 등장한 문서의 수\n",
        "  for doc in docs:\n",
        "    df += t in doc\n",
        "  return log(N/(df+1))+1\n",
        "\n",
        "def tfidf(t, d):\n",
        "  return tf(t,d) * idf(t)\n",
        "\n",
        "result = []\n",
        "for i in range(N):\n",
        "  result.append([])\n"
      ],
      "metadata": {
        "id": "08kRWbnDJ8Kn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}